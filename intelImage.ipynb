{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\yingz\\anaconda3\\lib\\site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: numpy in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0+cu118 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchvision) (2.3.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch==2.3.0+cu118->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0+cu118->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0+cu118->torchvision) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.0+cu118->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.0+cu118->torchvision) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\yingz\\anaconda3\\lib\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchmetrics) (2.3.0+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torchmetrics) (0.11.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yingz\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision\n",
    "%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
      "{0: 2191, 1: 2271, 2: 2404, 3: 2512, 4: 2274, 5: 2382}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    'archive/seg_train/seg_train', transform= transform)\n",
    "dataloader_train = DataLoader(train_dataset, shuffle=True,batch_size= 32, num_workers=4)\n",
    "print(train_dataset.classes)\n",
    "print(train_dataset.class_to_idx)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    'archive/seg_test/seg_test', transform= transform\n",
    ")\n",
    "dataloader_test = DataLoader(test_dataset, shuffle=True, batch_size= 32, num_workers=4)\n",
    "print(test_dataset.classes)\n",
    "print(test_dataset.class_to_idx)\n",
    "\n",
    "print(dict(Counter(train_dataset.targets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 150, 150])\n",
      "Shape after squeezing channel dimension: torch.Size([32, 3, 150, 150])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after squeezing channel dimension:\u001b[39m\u001b[38;5;124m\"\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 7\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "#Look at the data\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)\n",
    "image = image.squeeze(0)\n",
    "print(\"Shape after squeezing channel dimension:\", image.shape)\n",
    "\n",
    "image = image.permute(1, 2, 0)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Neural Network\n",
    "class Intel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.mod = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size= 3, padding= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size= 2),\n",
    "            nn.Conv2d(32, 64, kernel_size= 3, padding= 1),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size= 2),\n",
    "            nn.Conv2d(64, 128, kernel_size= 3, padding= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size= 2),\n",
    "            nn.Flatten(),\n",
    "            #nn.Dropout(0.3),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mod(x)\n",
    "        x = self.fc1(x) \n",
    "        return self.fc2(x)\n",
    "\n",
    "inte = Intel(num_classes= 6)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(inte.parameters(), lr=0.002)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "inte.to(device)\n",
    "\n",
    "for epoch in range(5):\n",
    "        for images , labels in dataloader_train:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = inte(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5700, device='cuda:0')\n",
      "tensor(0.6229, device='cuda:0')\n",
      "tensor(0.5728, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "met_accuracy = Accuracy(task='multiclass', num_classes= 6).to(device)\n",
    "metric_precision = Precision( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "metric_recall = Recall( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "inte.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = inte(images)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        met_accuracy.update(preds, labels)\n",
    "        metric_precision.update(preds, labels)\n",
    "        metric_recall.update(preds, labels)\n",
    "    accuracy = met_accuracy.compute()\n",
    "    precision = metric_precision.compute()\n",
    "    recall = metric_recall.compute()\n",
    "# test commit\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we test the accuracy of pre-trained models\n",
    "# Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "EPOCH 2:\n",
      "EPOCH 3:\n",
      "EPOCH 4:\n",
      "EPOCH 5:\n",
      "EPOCH 6:\n",
      "EPOCH 7:\n",
      "EPOCH 8:\n",
      "EPOCH 9:\n",
      "EPOCH 10:\n",
      "for  0.003  :  tensor(0.8870, device='cuda:0')\n",
      "tensor(0.8950, device='cuda:0')\n",
      "tensor(0.8907, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i in [0.003]: #0.003\n",
    "    #initalize model and freeze layers while adding our own\n",
    "    res = models.resnet50(weights= 'IMAGENET1K_V1')\n",
    "    for param in res.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_ftrs = res.fc.in_features\n",
    "\n",
    "    res.fc = nn.Sequential (nn.Linear(num_ftrs, 128),\n",
    "                            nn.Linear(128, 64),\n",
    "                            nn.Linear(64, 6),\n",
    "                            )\n",
    "\n",
    "    res = res.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    #initalize optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(res.fc.parameters(), lr= i)\n",
    "    \n",
    "    #train in epochs\n",
    "    for epoch in range(10):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "        for images , labels in dataloader_train:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = res(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "    #setup metrics\n",
    "    met_accuracy = Accuracy(task='multiclass', num_classes= 6).to(device)\n",
    "    metric_precision = Precision( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "    metric_recall = Recall( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "    \n",
    "    #evaluate our model on test\n",
    "    res.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader_test:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = res(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            met_accuracy.update(preds, labels)\n",
    "            metric_precision.update(preds, labels)\n",
    "            metric_recall.update(preds, labels)\n",
    "        accuracy = met_accuracy.compute()\n",
    "        precision = metric_precision.compute()\n",
    "        recall = metric_recall.compute()\n",
    "        \n",
    "    # test commit\n",
    "    print('for ', i, ' : ' ,accuracy)\n",
    "    print(precision)\n",
    "    print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "ttt = Image.open('./gla.jpg')\n",
    "ttt = transform(ttt)\n",
    "ttt = ttt.unsqueeze(0)\n",
    "ttt = ttt.to(device)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    output = res(ttt)\n",
    "\n",
    "# Get the predicted class\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(f'Predicted class: {predicted.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_pkl_file = \"intel_img_resnet50.pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(res, file)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8700, device='cuda:0')\n",
      "tensor(0.8761, device='cuda:0')\n",
      "tensor(0.8730, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "loaded_res = pickle.load(open(\"intel_img_resnet50.pkl\"  , 'rb'))    \n",
    "\n",
    "met_accuracy = Accuracy(task='multiclass', num_classes= 6).to(device)\n",
    "metric_precision = Precision( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "metric_recall = Recall( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "loaded_res.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = loaded_res(images)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        met_accuracy.update(preds, labels)\n",
    "        metric_precision.update(preds, labels)\n",
    "        metric_recall.update(preds, labels)\n",
    "    accuracy = met_accuracy.compute()\n",
    "    precision = metric_precision.compute()\n",
    "    recall = metric_recall.compute()\n",
    "# test commit\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "EPOCH 2:\n",
      "EPOCH 3:\n",
      "EPOCH 4:\n",
      "EPOCH 5:\n",
      "for  0.003  :  tensor(0.8710, device='cuda:0')\n",
      "tensor(0.8754, device='cuda:0')\n",
      "tensor(0.8739, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg = models.vgg19(weights='IMAGENET1K_V1')\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#num_ftrs = vgg.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "vgg.classifier[6] = nn.Linear(vgg.classifier[6].in_features, 6)\n",
    "\n",
    "vgg = vgg.to(device)\n",
    "\n",
    "\n",
    "\n",
    "for i in [0.003]: #0.003\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(vgg.classifier[6].parameters(), lr= i)\n",
    "    for epoch in range(5):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "        for images , labels in dataloader_train:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = vgg(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "                \n",
    "    met_accuracy = Accuracy(task='multiclass', num_classes= 6).to(device)\n",
    "    metric_precision = Precision( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "    metric_recall = Recall( task=\"multiclass\", num_classes=6, average=\"macro\").to(device)\n",
    "    vgg.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader_test:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = vgg(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            met_accuracy.update(preds, labels)\n",
    "            metric_precision.update(preds, labels)\n",
    "            metric_recall.update(preds, labels)\n",
    "        accuracy = met_accuracy.compute()\n",
    "        precision = metric_precision.compute()\n",
    "        recall = metric_recall.compute()\n",
    "        \n",
    "    # test commit\n",
    "    print('for ', i, ' : ' ,accuracy)\n",
    "    print(precision)\n",
    "    print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_file_2 = \"intel_img_vgg.pkl\"  \n",
    "\n",
    "with open(model_pkl_file_2, 'wb') as file:  \n",
    "    pickle.dump(vgg, file)\n",
    "    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
